'''
ë„¤, ì•Œê² ìŠµë‹ˆë‹¤. ì œê³µí•´ì£¼ì‹  JSON êµ¬ì¡°ë¥¼ ìš”ì²­í•˜ì‹  í˜•ì‹ì˜ ìŠ¤í‚¤ë§ˆë¡œ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

```
/*
================================================================================
|                        Firebase Realtime Database Schema               |
================================================================================

/ (root)
|
|--- mainPage/
|    |
|    |--- monthlyRanking: (Array) ì›”ê°„ ë­í‚¹ ëª©ë¡.
|    |    |--- [0]: { classId: (String), className: (String), monthlyUsageIndex: (Number) }
|    |    |--- [1]: ...
|    |
|    |--- systemIndexChangeVsLastWeek: (Number) ì „ì²´ ì‹œìŠ¤í…œì˜ ì§€ë‚œì£¼ ëŒ€ë¹„ ì¦ê°ë¥  (%).
|    |
|    `--- lastUpdated: (String) ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ (ISO 8601).
|
|--- detailPage/
|    |
|    |--- {classId}/ (e.g., "1-1", "1-2", ...)
|    |    |
|    |    |--- className: (String) í•™ê¸‰ ì´ë¦„.
|    |    |
|    |    |--- summary/
|    |    |    |--- dailyUsageIndex: (Number) ì¼ê°„ ì‚¬ìš© ì§€ìˆ˜.
|    |    |    |--- weeklyUsageIndex: (Number) ì£¼ê°„ ì‚¬ìš© ì§€ìˆ˜.
|    |    |    `--- monthlyUsageIndex: (Number) ì›”ê°„ ì‚¬ìš© ì§€ìˆ˜.
|    |    |
|    |    |--- comparison/
|    |    |    |--- vsLastDay: (Number) ì–´ì œ ëŒ€ë¹„ ì¦ê°ë¥  (%).
|    |    |    |--- vsLastWeek: (Number) ì§€ë‚œì£¼ ëŒ€ë¹„ ì¦ê°ë¥  (%).
|    |    |    `--- vsLastMonth: (Number) ì§€ë‚œë‹¬ ëŒ€ë¹„ ì¦ê°ë¥  (%).
|    |    |
|    |    `--- trends/
|    |         |--- last7Days: (Array) ì§€ë‚œ 7ì¼ê°„ì˜ ì¼ë³„ ë°ì´í„°.
|    |         |    `--- [0]: { date: (String), value: (Number) }
|    |         |
|    |         |--- last4Weeks: (Array) ì§€ë‚œ 4ì£¼ê°„ì˜ ì£¼ë³„ ë°ì´í„°.
|    |         |    `--- [0]: { week: (String), value: (Number) }
|    |         |
|    |         `--- todayRealtime: (Array) ì˜¤ëŠ˜ì˜ ì‹¤ì‹œê°„ ë°ì´í„°.
|    |              `--- [0]: { time: (String), value: (Number) }
|
`--- comparisonPage/
     |
     |--- summary/
     |    |--- dailyTotalIndex: (Number) ì „ì²´ ì¼ê°„ ì´í•© ì§€ìˆ˜.
     |    |--- weeklyTotalIndex: (Number) ì „ì²´ ì£¼ê°„ ì´í•© ì§€ìˆ˜.
     |    `--- monthlyTotalIndex: (Number) ì „ì²´ ì›”ê°„ ì´í•© ì§€ìˆ˜.
     |
     |--- comparison/
     |    |--- vsYesterday: (Number) ì „ì²´ ì–´ì œ ëŒ€ë¹„ ì¦ê°ë¥  (%).
     |    |--- vsLastWeek: (Number) ì „ì²´ ì§€ë‚œì£¼ ëŒ€ë¹„ ì¦ê°ë¥  (%).
     |    `--- vsLastMonth: (Number) ì „ì²´ ì§€ë‚œë‹¬ ëŒ€ë¹„ ì¦ê°ë¥  (%).
     |
     |--- classTrends: (Array) ê° ë°˜ì˜ ìƒì„¸ ì¶”ì´ ë°ì´í„° ëª©ë¡.
     |    `--- [0]: { classId: (String), last7Days: (Array), last4Weeks: (Array), todayRealtime: (Array) }
     |
     `--- lastUpdated: (String) ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ (ISO 8601).

*/


================================================================================
|                        Firestore Database Schema                             |
================================================================================
ğŸ—„ï¸ ac_logs (ì»¬ë ‰ì…˜)
  â””â”€â”€ ğŸ“„ {ìë™ ìƒì„± ID_1} (ë¬¸ì„œ)      <- ë¡œê·¸ 1ê°œ
      â”œâ”€â”€ classId: "1-1"
      â”œâ”€â”€ timestamp: ...
      â”œâ”€â”€ isOn: true
      â”œâ”€â”€ mode: "ëƒ‰ë°©"
      â”œâ”€â”€ temperature: 24.5
      â””â”€â”€ fanSpeed: "ê°•í’"

  â””â”€â”€ ğŸ“„ {ìë™ ìƒì„± ID_2} (ë¬¸ì„œ)      <- ë¡œê·¸ 1ê°œ
      â””â”€â”€ ...


ğŸ—„ï¸ class_stats (ì»¬ë ‰ì…˜)
  â””â”€â”€ ğŸ“ 1-1 (ë¬¸ì„œ)                   <- ë°˜ë³„ ë°ì´í„°ë¥¼ ë‹´ëŠ” ì»¨í…Œì´ë„ˆ
      â””â”€â”€ ğŸ—„ï¸ daily_history (ì„œë¸Œì»¬ë ‰ì…˜) <- ì¼ë³„ ê¸°ë¡ì„ ë‹´ëŠ” ì±…ì¥
          â””â”€â”€ ğŸ“„ 2025-10-08 (ë¬¸ì„œ)     <- í•˜ë£¨ì¹˜ ê¸°ë¡ íŒŒì¼
              â”‚
              â”œâ”€â”€ cumulative_by_time (ë§µ)  <- ì‹œê°„ëŒ€ë³„ ëˆ„ì  ì§€ìˆ˜
              â”‚   â”‚
              â”‚   â”œâ”€â”€ "09:00": 50        <- 9ì‹œ 00ë¶„ê¹Œì§€ì˜ ëˆ„ì ê°’
              â”‚   â”œâ”€â”€ "09:05": 58        <- 9ì‹œ 05ë¶„ê¹Œì§€ì˜ ëˆ„ì ê°’
              â”‚   â””â”€â”€ ...
              â”‚
              â””â”€â”€ finalTotal: 1390 (ìˆ«ì) <- í•´ë‹¹ ë‚ ì§œì˜ ìµœì¢… ë§ˆê° ì§€ìˆ˜

          â””â”€â”€ ğŸ“„ 2025-10-07 (ë¬¸ì„œ)
              â””â”€â”€ ...

        
```
'''
# main.py

from datetime import datetime, timedelta, timezone
from firebase_functions import options, scheduler_fn
import logging as logger
from firebase_admin import initialize_app, firestore, db

# --- ì´ˆê¸° ì„¤ì • ---
initialize_app()
options.set_global_options(region="asia-northeast3", memory=options.MemoryOption.MB_256)
# -----------------

# =================================================================================
# |                         10ë¶„ë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ë©”ì¸ í•¨ìˆ˜                              |
# =================================================================================

#@https_fn.on_call
@scheduler_fn.on_schedule(schedule="every 10 minutes")
def analyze_and_update_data(event: scheduler_fn.ScheduledEvent) -> None:
    """
    10ë¶„ë§ˆë‹¤ ì‹¤í–‰ë˜ì–´ ì‹¤ì‹œê°„ ë°ì´í„° ì§‘ê³„ ë° Realtime DB ì—…ë°ì´íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    logger.info("âœ… (10ë¶„ ì£¼ê¸°) ë°ì´í„° ë¶„ì„ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        # 1. Firestore 'ac_logs'ì—ì„œ ìµœê·¼ 10ë¶„ê°„ì˜ ë¡œê·¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        recent_logs = _get_recent_logs()
        if not recent_logs:
            logger.info("- ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ì–´ ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return

        # 2. ë¡œê·¸ì— ë¯¸ë¦¬ ê³„ì‚°ëœ usageIndexë¥¼ ë°˜ë³„ë¡œ í•©ì‚°í•©ë‹ˆë‹¤.
        new_points_by_class = _aggregate_indexes_from_logs(recent_logs)

        # 3. Firestore 'daily_history'ì— ì‹œê°„ëŒ€ë³„ ëˆ„ì  ê°’ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        updated_daily_docs = _update_firestore_history(new_points_by_class)

        # 4. ì—…ë°ì´íŠ¸ëœ ìµœì‹  ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ Realtime DBìš© ìµœì¢… JSONì„ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        #_create_and_save_rtdb_data(updated_daily_docs)

        logger.info("ğŸ‰ (10ë¶„ ì£¼ê¸°) ë°ì´í„° ë¶„ì„ ë° ì €ì¥ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ğŸ”¥ (10ë¶„ ì£¼ê¸°) ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

# =================================================================================
# |                          ìì •ë§ˆë‹¤ ì‹¤í–‰ë˜ëŠ” ë§ˆê° í•¨ìˆ˜                             |
# =================================================================================
@scheduler_fn.on_schedule(schedule="59 23 * * *", timezone=scheduler_fn.Timezone("Asia/Seoul"))
def finalize_daily_stats(event: scheduler_fn.ScheduledEvent) -> None:
    """
    ë§¤ì¼ 23ì‹œ 59ë¶„ì— ì‹¤í–‰ë˜ì–´ ê·¸ë‚ ì˜ ë°ì´í„°ë¥¼ ìµœì¢… ë§ˆê° ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    logger.info("âœ… (ìì • ì£¼ê¸°) ì¼ì¼ ë°ì´í„° ë§ˆê° ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    try:
        yesterday_str = (datetime.now(timezone(timedelta(hours=9))) - timedelta(days=1)).strftime('%Y-%m-%d')
        firestore_db = firestore.client()
        
        # ëª¨ë“  ë°˜ì˜ ì–´ì œ ì daily_history ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        class_stats_ref = firestore_db.collection("class_stats")
        for class_doc in class_stats_ref.stream():
            class_id = class_doc.id
            yesterday_doc_ref = class_stats_ref.document(class_id).collection("daily_history").document(yesterday_str)
            yesterday_doc = yesterday_doc_ref.get()

            if yesterday_doc.exists:
                cumulative_map = yesterday_doc.to_dict().get("cumulative_by_time", {})
                if cumulative_map:
                    # ê·¸ë‚ ì˜ ê°€ì¥ ë§ˆì§€ë§‰ ëˆ„ì  ê°’ì„ ì°¾ì•„ finalTotalë¡œ ì €ì¥í•©ë‹ˆë‹¤.
                    final_total = max(cumulative_map.values())
                    yesterday_doc_ref.update({"finalTotal": round(final_total)})
                    logger.info(f"- {class_id}ë°˜ {yesterday_str}ì˜ ìµœì¢…ê°’ {round(final_total)}ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        logger.info("ğŸ‰ (ìì • ì£¼ê¸°) ì¼ì¼ ë°ì´í„° ë§ˆê° ì‘ì—…ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ğŸ”¥ (ìì • ì£¼ê¸°) ì‘ì—… ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")

# =================================================================================
# |                                  í—¬í¼ í•¨ìˆ˜ë“¤                                   |
# =================================================================================

def _get_recent_logs() -> list:
    """Firestore 'ac_logs' ì»¬ë ‰ì…˜ì—ì„œ ìµœê·¼ 10ë¶„ ì´ë‚´ì˜ ë¬¸ì„œë¥¼ ì¡°íšŒí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."""
    firestore_db = firestore.client()
    utc_now = datetime.now(timezone.utc)
    ten_minutes_ago = utc_now - timedelta(minutes=10)
    
    logs_query = firestore_db.collection("ac_logs").where("timestamp", ">=", ten_minutes_ago).stream()
    
    logs = [doc.to_dict() for doc in logs_query]
    logger.info(f"- Firestoreì—ì„œ {len(logs)}ê°œì˜ ìƒˆ ë¡œê·¸ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    return logs

def _aggregate_indexes_from_logs(logs: list) -> dict:
    """ë¡œê·¸ ëª©ë¡ì„ ë°›ì•„, ë¯¸ë¦¬ ê³„ì‚°ëœ usageIndexë¥¼ ë°˜ë³„ë¡œ í•©ì‚°í•©ë‹ˆë‹¤."""
    points_by_class = {}
    for log in logs:
        class_id = log.get("classId")
        usage_index = log.get("usageIndex", 0.0)
        if not class_id:
            continue
        points_by_class[class_id] = points_by_class.get(class_id, 0.0) + usage_index
    return points_by_class

def _update_firestore_history(points_by_class: dict) -> dict:
    """ê³„ì‚°ëœ ìƒˆ ì§€ìˆ˜ë¥¼ Firestore 'daily_history'ì˜ ê° ë¬¸ì„œì— ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    firestore_db = firestore.client()
    today_str = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d')
    now_time_str = datetime.now(timezone(timedelta(hours=9))).strftime('%H:%M')
    
    updated_docs = {}

    for class_id, new_points in points_by_class.items():
        doc_ref = firestore_db.collection("class_stats").document(class_id).collection("daily_history").document(today_str)
        doc = doc_ref.get()
        
        cumulative_map = {}
        if doc.exists:
            cumulative_map = doc.to_dict().get("cumulative_by_time", {})
        
        last_cumulative_value = max(cumulative_map.values()) if cumulative_map else 0.0
        new_cumulative_value = last_cumulative_value + new_points
        
        cumulative_map[now_time_str] = new_cumulative_value
        
        # Firestoreì— ì—…ë°ì´íŠ¸
        doc_ref.set({"cumulative_by_time": cumulative_map}, merge=True)
        updated_docs[class_id] = cumulative_map
        
    logger.info(f"- {today_str} Firestore ì¼ì¼ ì›ì¥ì„ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
    return updated_docs

# í—¬í¼ í•¨ìˆ˜ë“¤ ë‚´ì—ì„œ ì‚¬ìš©í•  ì‹œê°„ëŒ€ ì„¤ì • (í•œêµ­ ì‹œê°„)
KST = timezone(timedelta(hours=9))

def _get_all_historical_data() -> dict:
    """
    ê³„ì‚°ì— í•„ìš”í•œ ëª¨ë“  ë°˜ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ Firestoreì—ì„œ í•œ ë²ˆì— ê°€ì ¸ì˜µë‹ˆë‹¤.
    ì•½ 40ì¼ ì „ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì—¬ ì›”ê°„ ë¹„êµê¹Œì§€ ì¶©ë¶„íˆ ì»¤ë²„í•©ë‹ˆë‹¤.
    """
    firestore_db = firestore.client()
    # ë¹„êµ ê³„ì‚°ì„ ìœ„í•´ ì•½ 40ì¼ ì „ ë°ì´í„°ê¹Œì§€ ì¡°íšŒ
    start_date_str = (datetime.now(KST) - timedelta(days=40)).strftime('%Y-%m-%d')
    
    historical_data = {}
    class_stats_ref = firestore_db.collection("class_stats")
    
    for class_doc in class_stats_ref.stream():
        class_id = class_doc.id
        historical_data[class_id] = {}
        
        # ê° ë°˜ì˜ daily_history ì„œë¸Œì»¬ë ‰ì…˜ì—ì„œ 40ì¼ì¹˜ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜´
        daily_docs_query = class_doc.reference.collection("daily_history").where(firestore.FieldPath.document_id(), ">=", start_date_str)
        
        for daily_doc in daily_docs_query.stream():
            historical_data[class_id][daily_doc.id] = daily_doc.to_dict()
            
    logger.info(f"- {len(historical_data)}ê°œ ë°˜ì˜ ê³¼ê±° ë°ì´í„°ë¥¼ Firestoreì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
    return historical_data

def _generate_usage_metrics(class_id: str, today_cumulative_map: dict, historical_data: dict, now: datetime) -> dict:
    """
    í•œ ê°œ ë°˜ì˜ 'ì˜¤ëŠ˜/ì´ë²ˆ ì£¼/ì´ë²ˆ ë‹¬' ëˆ„ì  ì‚¬ìš© ì§€ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    :param class_id: ê³„ì‚°í•  ë°˜ì˜ ID (ì˜ˆ: "1-1")
    :param today_cumulative_map: ì˜¤ëŠ˜ í˜„ì¬ê¹Œì§€ì˜ ì‹œê°„ëŒ€ë³„ ëˆ„ì ê°’ ë§µ
    :param historical_data: ëª¨ë“  ê³¼ê±° ë°ì´í„°ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬
    :param now: ê¸°ì¤€ ì‹œê°
    :return: summary ê°ì²´ ë”•ì…”ë„ˆë¦¬
    """
    
    # 1. ì˜¤ëŠ˜ ëˆ„ì  ì§€ìˆ˜ ê³„ì‚°
    daily_index = max(today_cumulative_map.values()) if today_cumulative_map else 0

    # 2. ì´ë²ˆ ì£¼ ëˆ„ì  ì§€ìˆ˜ ê³„ì‚°
    weekly_index = daily_index
    # ì˜¤ëŠ˜ì´ ì›”ìš”ì¼ì´ ì•„ë‹ˆë¼ë©´, ì´ë²ˆ ì£¼ ì›”ìš”ì¼ë¶€í„° ì–´ì œê¹Œì§€ì˜ finalTotalì„ ë”í•´ì¤Œ
    for i in range(1, now.weekday()): # ì›”ìš”ì¼(0) ~ ì¼ìš”ì¼(6)
        day_to_add = (now - timedelta(days=i)).strftime('%Y-%m-%d')
        weekly_index += historical_data.get(class_id, {}).get(day_to_add, {}).get("finalTotal", 0)

    # 3. ì´ë²ˆ ë‹¬ ëˆ„ì  ì§€ìˆ˜ ê³„ì‚°
    monthly_index = daily_index
    # ì˜¤ëŠ˜ì´ 1ì¼ì´ ì•„ë‹ˆë¼ë©´, ì´ë²ˆ ë‹¬ 1ì¼ë¶€í„° ì–´ì œê¹Œì§€ì˜ finalTotalì„ ë”í•´ì¤Œ
    for i in range(1, now.day):
        day_to_add = (now - timedelta(days=i)).strftime('%Y-%m-%d')
        monthly_index += historical_data.get(class_id, {}).get(day_to_add, {}).get("finalTotal", 0)

    return {
        "dailyUsageIndex": round(daily_index),
        "weeklyUsageIndex": round(weekly_index),
        "monthlyUsageIndex": round(monthly_index)
    }

def _get_point_in_time_value(history_map: dict, target_time: str) -> float:
    """'HH:MM' í˜•ì‹ì˜ ì‹œê°„ëŒ€ë³„ ëˆ„ì  ë§µì—ì„œ íŠ¹ì • ì‹œê°„ì˜ ê°’ì„ ì°¾ì•„ ë°˜í™˜í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"""
    if target_time in history_map:
        return history_map[target_time]
    
    # ì •í™•í•œ ì‹œê°„ì´ ì—†ìœ¼ë©´, ê·¸ ì‹œê°„ ë°”ë¡œ ì´ì „ì˜ ë§ˆì§€ë§‰ ê°’ì„ ì°¾ìŒ
    available_times = sorted([t for t in history_map.keys() if t <= target_time], reverse=True)
    return history_map[available_times[0]] if available_times else 0.0
# main.py íŒŒì¼ì˜ í—¬í¼ í•¨ìˆ˜ ì„¹ì…˜ì— ì•„ë˜ ì½”ë“œë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ëŒ€ì²´í•˜ì„¸ìš”.

# ì´ í•¨ìˆ˜ëŠ” _generate_comparison_metrics ì•ˆì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
def _get_point_in_time_value(history_map: dict, target_time: str) -> float:
    """'HH:MM' í˜•ì‹ì˜ ì‹œê°„ëŒ€ë³„ ëˆ„ì  ë§µì—ì„œ íŠ¹ì • ì‹œê°„ ë˜ëŠ” ê·¸ ì´ì „ì˜ ë§ˆì§€ë§‰ ê°’ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not history_map:
        return 0.0
    if target_time in history_map:
        return history_map[target_time]
    
    # ì •í™•í•œ ì‹œê°„ì´ ì—†ìœ¼ë©´, ê·¸ ì‹œê°„ ë°”ë¡œ ì´ì „ì˜ ë§ˆì§€ë§‰ ê°’ì„ ì°¾ìŠµë‹ˆë‹¤.
    available_times = sorted([t for t in history_map.keys() if t <= target_time], reverse=True)
    return history_map[available_times[0]] if available_times else 0.0

def _generate_comparison_metrics(class_id: str, today_cumulative_map: dict, historical_data: dict, now: datetime) -> dict:
    """
    í•œ ê°œ ë°˜ì˜ 'ì–´ì œ/ì§€ë‚œì£¼/ì§€ë‚œë‹¬' ëŒ€ë¹„ ì‹œì ë³„ ë³€í™”ìœ¨(%)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    :param class_id: ê³„ì‚°í•  ë°˜ì˜ ID
    :param today_cumulative_map: ì˜¤ëŠ˜ í˜„ì¬ê¹Œì§€ì˜ ì‹œê°„ëŒ€ë³„ ëˆ„ì ê°’ ë§µ
    :param historical_data: ëª¨ë“  ê³¼ê±° ë°ì´í„°ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬
    :param now: ê¸°ì¤€ ì‹œê°
    :return: comparison ê°ì²´ ë”•ì…”ë„ˆë¦¬
    """
    now_time_str = now.strftime('%H:%M')
    
    class_history = historical_data.get(class_id, {})

    # --- ì–´ì œ ëŒ€ë¹„ (vsLastDay) ---
    today_val = _get_point_in_time_value(today_cumulative_map, now_time_str)
    
    yesterday_str = (now - timedelta(days=1)).strftime('%Y-%m-%d')
    yesterday_history = class_history.get(yesterday_str, {}).get("cumulative_by_time", {})
    yesterday_val = _get_point_in_time_value(yesterday_history, now_time_str)
    
    vs_last_day = ((today_val / yesterday_val) - 1) * 100 if yesterday_val > 0 else 0.0

    # --- ì§€ë‚œì£¼ ëŒ€ë¹„ (vsLastWeek) ---
    # ì´ë²ˆ ì£¼ í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ëˆ„ì ê°’ ê³„ì‚°
    current_weekly_total = today_val
    for i in range(1, now.weekday() + 1): # ì›”ìš”ì¼(0)ë¶€í„° ì–´ì œê¹Œì§€
        day_str = (now - timedelta(days=i)).strftime('%Y-%m-%d')
        current_weekly_total += class_history.get(day_str, {}).get("finalTotal", 0)

    # ì§€ë‚œì£¼ ê°™ì€ ì‹œì ê¹Œì§€ì˜ ëˆ„ì ê°’ ê³„ì‚°
    last_week_point_date = now - timedelta(weeks=1)
    last_week_point_date_str = last_week_point_date.strftime('%Y-%m-%d')
    last_week_point_history = class_history.get(last_week_point_date_str, {}).get("cumulative_by_time", {})
    last_week_point_val = _get_point_in_time_value(last_week_point_history, last_week_point_date.strftime('%H:%M'))
    
    last_week_total_at_point = last_week_point_val
    for i in range(1, last_week_point_date.weekday() + 1):
        day_str = (last_week_point_date - timedelta(days=i)).strftime('%Y-%m-%d')
        last_week_total_at_point += class_history.get(day_str, {}).get("finalTotal", 0)

    vs_last_week = ((current_weekly_total / last_week_total_at_point) - 1) * 100 if last_week_total_at_point > 0 else 0.0
    
    # --- ì§€ë‚œë‹¬ ëŒ€ë¹„ (vsLastMonth) ---
    # ì´ë²ˆ ë‹¬ í˜„ì¬ ì‹œì ê¹Œì§€ì˜ ëˆ„ì ê°’ ê³„ì‚°
    current_monthly_total = today_val
    for i in range(1, now.day):
        day_str = (now - timedelta(days=i)).strftime('%Y-%m-%d')
        current_monthly_total += class_history.get(day_str, {}).get("finalTotal", 0)

    # ì§€ë‚œë‹¬ ê°™ì€ ì‹œì  ë‚ ì§œ ê³„ì‚° (ì˜ˆ: 3ì›” 31ì¼ì˜ í•œë‹¬ ì „ì€ 2ì›” 28/29ì¼)
    last_month_point_date = now - timedelta(days=30) # ê°„ë‹¨í•œ ê·¼ì‚¬ì¹˜, ë” ì •í™•í•˜ê²Œ í•˜ë ¤ë©´ dateutil ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
    last_month_point_date_str = last_month_point_date.strftime('%Y-%m-%d')
    last_month_point_history = class_history.get(last_month_point_date_str, {}).get("cumulative_by_time", {})
    last_month_point_val = _get_point_in_time_value(last_month_point_history, last_month_point_date.strftime('%H:%M'))
    
    last_month_total_at_point = last_month_point_val
    for i in range(1, last_month_point_date.day):
        day_str = (last_month_point_date - timedelta(days=i)).strftime('%Y-%m-%d')
        last_month_total_at_point += class_history.get(day_str, {}).get("finalTotal", 0)
        
    vs_last_month = ((current_monthly_total / last_month_total_at_point) - 1) * 100 if last_month_total_at_point > 0 else 0.0

    return {
        "vsLastDay": round(vs_last_day, 1),
        "vsLastWeek": round(vs_last_week, 1),
        "vsLastMonth": round(vs_last_month, 1)
    }


"""
def _create_and_save_rtdb_data(updated_daily_docs):

    # 1. ê³„ì‚°ì— í•„ìš”í•œ ëª¨ë“  ê³¼ê±° ë°ì´í„°ë¥¼ Firestoreì—ì„œ ë”± í•œ ë²ˆë§Œ ë¶ˆëŸ¬ì˜¨ë‹¤.
    historical_data = _get_all_historical_data() 
    
    final_rtdb_data = { ... } # ìµœì¢… JSON í…œí”Œë¦¿
    all_class_ids = ["1-1", "1-2", "1-3", "1-4", "1-5", "1-6"]

    # 2. ë©”ëª¨ë¦¬ì— ìˆëŠ” ë°ì´í„°ë¥¼ ê°€ì§€ê³  ê° ë°˜ì˜ ì§€í‘œë¥¼ ê³„ì‚°í•œë‹¤.
    for class_id in all_class_ids:
        
        # 'ì˜¤ëŠ˜'ì˜ ìµœì‹  ë°ì´í„°ëŠ” updated_daily_docsì—ì„œ ê°€ì ¸ì˜´
        today_data = updated_daily_docs.get(class_id)

        # (ê³„ì‚° ì „ë¬¸ê°€ 1) ë©”ëª¨ë¦¬ì˜ ê³¼ê±° ë°ì´í„°ë¡œ summary ê³„ì‚°
        summary = generate_usage_metrics(class_id, today_data, historical_data)
        
        # (ê³„ì‚° ì „ë¬¸ê°€ 2) ë©”ëª¨ë¦¬ì˜ ê³¼ê±° ë°ì´í„°ë¡œ comparison ê³„ì‚°
        comparison = generate_comparison_metrics(class_id, today_data, historical_data)

        # ê³„ì‚° ê²°ê³¼ë¥¼ ìµœì¢… JSONì— ì±„ì›Œë„£ê¸°
        final_rtdb_data["detailPage"][class_id]["summary"] = summary
        final_rtdb_data["detailPage"][class_id]["comparison"] = comparison
        # ... trends ë“± ë‚˜ë¨¸ì§€ ë°ì´í„°ë„ ì±„ì›Œë„£ê¸° ...
    
    # 3. ëª¨ë“  ë°˜ì˜ ê³„ì‚°ì´ ëë‚œ í›„, ë­í‚¹ ë“± 2ì°¨ ê³„ì‚° ìˆ˜í–‰
    # ...

    # 4. ìµœì¢… JSONì„ Realtime DBì— ì €ì¥
    # ...
"""